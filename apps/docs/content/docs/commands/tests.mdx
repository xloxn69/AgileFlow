---
title: /setup-tests
description: Set up automated testing infrastructure
---

# /setup-tests

Automatically detect your project type and bootstrap a complete testing infrastructure with framework setup, configuration, example tests, and CI integration.

## Quick Start

```bash
/agileflow:setup-tests FRAMEWORK=auto COVERAGE=yes
```

## Purpose

This command creates a professional testing foundation by:
- Auto-detecting your project language and framework
- Installing appropriate testing framework dependencies
- Creating test configuration files
- Generating example unit, integration, and E2E tests
- Adding test scripts to your build configuration
- Integrating tests into CI/CD pipeline
- Creating testing documentation and best practices
- Running tests to verify the setup works

## Parameters

| Parameter | Required | Default | Description |
|-----------|----------|---------|-------------|
| `FRAMEWORK` | No | `auto` | `auto`, `jest`, `mocha`, `pytest`, `rspec`, `go-test`, `cargo-test` |
| `COVERAGE` | No | `yes` | Enable coverage reporting: `yes` or `no` |
| `E2E` | No | `no` | Include E2E tests: `yes` or `no` |

## Examples

### Auto-Detect and Setup

```bash
/agileflow:setup-tests
```

Detects Node.js/Python/Ruby/Go/Rust and installs appropriate framework.

### Force Specific Framework

```bash
/agileflow:setup-tests FRAMEWORK=jest COVERAGE=yes
```

Uses Jest for testing with coverage enabled.

### Include E2E Tests

```bash
/agileflow:setup-tests E2E=yes
```

Sets up unit, integration, AND end-to-end tests (Playwright for web apps).

### Python Project

```bash
/agileflow:setup-tests FRAMEWORK=pytest
```

Installs pytest with coverage and creates example tests.

## Project Detection

The command automatically detects your tech stack:

| Tech Stack | Framework | Detected By |
|-----------|-----------|-------------|
| Node.js | Jest | package.json |
| Node.js (older) | Mocha | package.json |
| Python | pytest | requirements.txt, pyproject.toml |
| Ruby | RSpec | Gemfile |
| Go | go test | go.mod |
| Rust | cargo test | Cargo.toml |
| Java | JUnit | pom.xml, build.gradle |
| .NET | xUnit/NUnit | *.csproj |

## Output Files

The command creates a complete testing setup:

### Configuration Files

**Jest** (`jest.config.js`):
```javascript
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  coverageDirectory: 'coverage',
  collectCoverageFrom: [
    'src/**/*.{js,ts}',
    '!src/**/*.d.ts',
  ],
  coverageThreshold: {
    global: {
      branches: 70,
      functions: 70,
      lines: 70,
      statements: 70
    }
  }
};
```

**pytest** (`pytest.ini`):
```ini
[pytest]
testpaths = tests
python_files = test_*.py *_test.py
addopts = --cov=src --cov-report=html --cov-report=term
```

**RSpec** (`.rspec`):
```
--format documentation
--require spec_helper
```

### Directory Structure

Creates organized test directories:

<Tree>
  <Folder element="tests" value="tests">
    <Folder element="unit" value="unit">
      <File value="example.test.ts">example.test.ts</File>
    </Folder>
    <Folder element="integration" value="integration">
      <File value="api.test.ts">api.test.ts</File>
    </Folder>
    <Folder element="e2e" value="e2e">
      <File value="login.spec.ts">login.spec.ts</File>
    </Folder>
    <Folder element="fixtures" value="fixtures">
      <File value="users.json">users.json</File>
    </Folder>
    <Folder element="helpers" value="helpers">
      <File value="setup.ts">setup.ts</File>
    </Folder>
  </Folder>
</Tree>

### Example Tests

**Unit Test** (`tests/unit/example.test.ts`):
```typescript
describe('Example Test Suite', () => {
  it('should pass this example test', () => {
    expect(true).toBe(true);
  });

  it('should test basic math', () => {
    expect(2 + 2).toBe(4);
  });
});
```

**Component Test** (`tests/components/Button.test.tsx`):
```typescript
import { render, screen, fireEvent } from '@testing-library/react';
import Button from '@/components/Button';

describe('Button Component', () => {
  it('renders with text', () => {
    render(<Button>Click Me</Button>);
    expect(screen.getByText('Click Me')).toBeInTheDocument();
  });

  it('calls onClick when clicked', () => {
    const handleClick = jest.fn();
    render(<Button onClick={handleClick}>Click</Button>);
    fireEvent.click(screen.getByText('Click'));
    expect(handleClick).toHaveBeenCalledTimes(1);
  });
});
```

**Integration Test** (`tests/integration/api.test.ts`):
```typescript
import request from 'supertest';
import app from '@/app';

describe('API Integration Tests', () => {
  it('GET / should return 200', async () => {
    const response = await request(app).get('/');
    expect(response.status).toBe(200);
  });

  it('POST /api/users should create user', async () => {
    const response = await request(app)
      .post('/api/users')
      .send({ name: 'Test User', email: 'test@example.com' });
    expect(response.status).toBe(201);
    expect(response.body).toHaveProperty('id');
  });
});
```

**E2E Test** (`tests/e2e/login.spec.ts`):
```typescript
import { test, expect } from '@playwright/test';

test('user can log in', async ({ page }) => {
  await page.goto('http://localhost:3000/login');
  await page.fill('input[name="email"]', 'test@example.com');
  await page.fill('input[name="password"]', 'password123');
  await page.click('button[type="submit"]');
  await expect(page).toHaveURL('http://localhost:3000/dashboard');
});
```

### NPM Scripts

Updated `package.json`:
```json
{
  "scripts": {
    "test": "jest",
    "test:watch": "jest --watch",
    "test:coverage": "jest --coverage",
    "test:unit": "jest tests/unit",
    "test:integration": "jest tests/integration",
    "test:e2e": "playwright test"
  }
}
```

### CI Integration

Adds test job to `.github/workflows/ci.yml`:
```yaml
test:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4

    - name: Setup Node
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Run tests
      run: npm test -- --coverage

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage/lcov.info
```

### Documentation

Creates `docs/02-practices/testing.md`:
```markdown
# Testing Guide

## Running Tests

npm test              # Run all tests
npm run test:watch    # Watch mode
npm run test:coverage # With coverage report
npm run test:unit     # Unit tests only

## Writing Tests

### Unit Tests
- Test individual functions/classes in isolation
- Mock external dependencies
- Fast (<10ms per test)

### Integration Tests
- Test multiple components together
- Use real dependencies when possible
- Medium speed (<100ms per test)

### E2E Tests
- Test full user flows
- Run against real app
- Slow (seconds per test)

## Coverage Requirements

- Minimum 70% coverage (enforced in CI)
- New code should be 90%+ covered
- Critical paths require 100% coverage

## Best Practices

- Use descriptive test names (Given/When/Then)
- One assertion per test when possible
- Avoid test interdependence
- Use factories/fixtures for test data
```

## Test Types

### Unit Tests
**What**: Test individual functions/classes in isolation
**Speed**: Fast (< 10ms each)
**Mocking**: Yes, mock dependencies
**Coverage**: Most code should have unit tests

Example: Test a utility function that calculates user age.

### Integration Tests
**What**: Test multiple components working together
**Speed**: Medium (< 100ms each)
**Mocking**: Minimal, use real components
**Coverage**: Critical workflows and API routes

Example: Test that authentication flow works end-to-end with database.

### E2E Tests (Optional)
**What**: Test complete user flows in real application
**Speed**: Slow (seconds per test)
**Mocking**: None, real application
**Coverage**: Critical user journeys only

Example: User signup → login → view dashboard flow.

## Coverage Thresholds

Default thresholds (reasonable, not perfectionist):
- **Branches**: 70% - All decision paths covered
- **Functions**: 70% - All functions called
- **Lines**: 70% - All lines executed
- **Statements**: 70% - All statements run

**Why not 100%?**
- 100% coverage doesn't guarantee 100% correctness
- Some code is hard to test (UI, edge cases)
- Diminishing returns after 70-80%
- Focus on critical paths instead

## Running Tests

### During Development
```bash
npm run test:watch
```
Auto-runs tests when files change.

### Before Commit
```bash
npm test
npm run test:coverage
```
Full test suite with coverage check.

### In CI
Automatically runs on every push:
```bash
npm test -- --coverage --ci
```

## Workflow

The setup follows these steps:

1. **Detect Language/Runtime**
   - Looks for package.json, Gemfile, go.mod, etc.
   - Determines appropriate framework

2. **Check Existing Setup**
   - Scans for test directories (test/, tests/, __tests__/)
   - Checks for test config files
   - Detects CI configuration

3. **Show Setup Plan**
   ```
   Will install:
   - jest, @types/jest, ts-jest
   - @testing-library/react

   Will create:
   - jest.config.js
   - tests/ directory structure
   - Example tests

   Will update:
   - package.json (test scripts)
   - .github/workflows/ci.yml (test job)

   Proceed? (YES/NO)
   ```

4. **Install Dependencies**
   - npm install, pip install, bundle install, etc.

5. **Create Configuration**
   - Framework-specific config files

6. **Generate Examples**
   - Unit test example
   - Integration test example
   - E2E test example (if requested)

7. **Update Scripts and CI**
   - Add test commands
   - Integrate with existing workflow

8. **Run Tests**
   - Verify setup works
   - Show coverage report

9. **Create Documentation**
   - Testing guide
   - Best practices
   - Coverage expectations

## Next Steps

After setup completes:

1. **Run Tests Locally**
   ```bash
   npm test
   npm run test:watch
   ```

2. **Write First Tests**
   - Start with unit tests for utilities
   - Add integration tests for APIs
   - Later add E2E tests for critical flows

3. **Enable Coverage Checks**
   - CI requires minimum coverage
   - Merge blocked if coverage drops

4. **Monitor Coverage Trends**
   - Use codecov.io or similar
   - Track coverage over time
   - Celebrate improvements

## Best Practices

1. **Write Tests Early** - TDD or alongside features
2. **Keep Tests Fast** - Mock slow operations
3. **Use Descriptive Names** - Test name explains what it tests
4. **One Assert Per Test** - When possible, makes failures clear
5. **DRY in Tests** - Use fixtures, factories, setup/teardown
6. **Test Behavior** - Not implementation details
7. **Avoid Flakiness** - No timing issues, random failures
8. **Clean Up** - Reset state between tests

## Related Commands

- [`/ci-setup`](/commands/ci) - Set up CI/CD workflow
- [`/setup-deployment`](/commands/deploy) - Configure deployment
- [`/packages`](/commands/packages) - Manage test dependencies
