---
title: QA Agent
description: QA specialist for test strategy, test planning, quality metrics, regression testing, and release readiness validation.
---

# QA Agent

The QA Agent (AG-QA) is a quality assurance specialist who ensures features meet quality standards before release. This agent focuses on test strategy, regression testing, quality metrics, and release readiness - complementing the Testing Agent who designs test implementations.

## Capabilities

- **Test Strategy Development**: Create comprehensive test plans with scope, coverage targets, and success criteria
- **Regression Testing**: Plan and manage regression test suites for releases
- **Quality Metrics**: Define and track KPIs (code coverage, bug escape rate, defect density)
- **Release Readiness**: Create and validate release checklists and sign-off procedures
- **Test Case Management**: Organize and manage manual test cases
- **Bug Triage**: Assess severity and prioritize issue resolution
- **UAT Planning**: Coordinate User Acceptance Testing with stakeholders
- **Quality Gates**: Define automated quality checkpoints in CI/CD pipeline

## When to Use

Use the QA Agent when:

- Planning a new release and need quality criteria
- Need to define test strategy with coverage targets
- Creating test cases for critical user workflows
- Setting up regression testing for releases
- Triaging bugs and assessing severity
- Planning User Acceptance Testing (UAT)
- Need to establish quality gates and exit criteria
- Creating release readiness checklists

## How It Works

1. **Knowledge Loading**: Agent reads expertise and project quality standards
2. **Feature Analysis**: Agent reviews story for testing needs
3. **Test Strategy**: Agent designs test plan with scope and coverage targets
4. **Test Planning**: Agent creates test cases and regression scope
5. **Quality Gates**: Agent defines quality metrics and thresholds
6. **Release Readiness**: Agent creates sign-off procedures and checklists
7. **Coordination**: Agent aligns with testing and development teams
8. **Verification**: Agent ensures quality criteria are met
9. **Documentation**: Agent updates status.json and quality reports

## Example

```bash
# Via babysit - define release quality criteria
/agileflow:babysit
> "We're preparing v2.1.0 for release. What's our release readiness?"

# Agent output:
# Release Readiness Assessment:
# - Code coverage: 82% (target: 80%) ✅
# - All automated tests passing: 523/523 ✅
# - Critical bugs: 0 ✅
# - Regression test scope: 15 core workflows
# - UAT sign-off: Pending
# - Performance baseline: Verified
# - Security review: In progress
#
# Release Recommendation: READY WITH CONDITIONS
# - Security review must complete before release
# - UAT sign-off required from product team
```

## Key Behaviors

- **Quality First**: Never release without meeting quality criteria
- **Test Early**: Testing happens throughout development, not just at end
- **Risk-Based**: Higher risk areas get more testing attention
- **Metrics-Driven**: Quality decisions backed by data and KPIs
- **Clear Criteria**: Release criteria documented and measurable
- **Regression Focused**: Automated regression tests prevent known bugs
- **User Sign-Off**: UAT validates user expectations before release

## Tools Available

- Read, Write, Edit (file operations)
- Bash (run quality reports)
- Glob (find test artifacts)
- Grep (analyze quality data)

## Quality Metrics Framework

**Coverage Metrics**:
- Code coverage: >80% unit, >60% integration, >30% E2E
- Feature coverage: % of features tested
- Requirement coverage: % of requirements tested

**Bug Metrics**:
- Bugs found: Total count
- Bug escape rate: % of bugs found in production vs testing (target: under 2%)
- Defect density: Bugs per 1000 lines of code (target: under 2.5)

**Quality KPIs**:
- Test pass rate: >95%
- Mean time to fix: Average time from report to resolution
- Regression rate: % of regressions in releases

## Release Readiness Checklist

**Must Have Before Release**:
- [ ] Code review completed (100% coverage)
- [ ] All automated tests passing
- [ ] Critical bugs resolved
- [ ] Performance baseline met
- [ ] Accessibility verified (WCAG AA)
- [ ] Security review passed
- [ ] Documentation updated
- [ ] UAT sign-off obtained

**Should Have Before Release**:
- [ ] High priority bugs resolved
- [ ] Performance optimized
- [ ] Load testing completed
- [ ] Monitoring set up

**Nice to Have Before Release**:
- [ ] Medium priority bugs resolved
- [ ] Performance benchmarks published
- [ ] User communication drafted

## Bug Severity Levels

| Severity | Description | Example | Priority |
|----------|-------------|---------|----------|
| Critical | Feature unusable, data loss, security breach | Users cannot log in | Fix immediately |
| High | Feature significantly impaired | Payment fails 50% of time | Fix ASAP |
| Medium | Feature works with limitations | Email delayed 2 hours | Schedule near future |
| Low | Minor issue, easy workaround | Button text misaligned | Backlog |

## Test Case Management

**Test Case Template**:
```
Test Case ID: TC-001
Title: User can log in with valid credentials
Feature: Authentication

Preconditions:
- User has registered account
- Login page accessible

Test Steps:
1. Navigate to login page
2. Enter email address
3. Enter password
4. Click "Sign In"

Expected Result:
- Dashboard loads in <2 seconds
- User data displayed correctly
- Welcome message shown

Status: ☐ Pass ☐ Fail ☐ Blocked
```

## Regression Testing Strategy

**What to Regress Test**:
- Core user workflows (login, signup, critical features)
- Changed features (affected by this release)
- Related features (dependencies)
- Critical paths (high-use features)
- Performance-sensitive areas
- Security-sensitive features

**Regression Scope Example**:
```
Feature: User Login
├── Happy path: Valid credentials
├── Invalid credentials: Wrong password
├── Inactive account: Suspended user
├── Password reset flow
├── Login rate limiting
├── Session management
└── Related features:
    ├── Signup (account creation)
    ├── Password change
    └── Session timeout
```

## User Acceptance Testing (UAT)

**UAT Preparation**:
- Identify stakeholders and users
- Create test scenarios from user stories
- Prepare production-like test environment
- Prepare realistic test data
- Schedule UAT sessions

**UAT Sign-Off**:
```
UAT Sign-Off Form

Project: [Project Name]
Version: [Version]
Date: [Date]

Tested By: [Name, Title]
Approved By: [Name, Title]

Overall Result: ☐ Approved ☐ With Conditions ☐ Rejected

Issues Found: [List]

Signature: ________________
```

## Quality Gates

**Code Quality Gate** (before merge):
- Code review approved
- Linting passed
- Type checking passed
- Unit tests passing (>80% coverage)
- No security vulnerabilities

**Integration Quality Gate** (before staging):
- Integration tests passing
- E2E tests passing
- Performance within baseline
- Database migrations validated
- API contracts validated

**Release Quality Gate** (before production):
- Regression testing passed
- UAT sign-off obtained
- Critical bugs resolved
- Performance benchmarks met
- Security review approved

## Related Agents

- [`testing`](/agents/testing) - Test implementation and coverage optimization
- [`ci`](/agents/ci) - CI/CD pipeline and test infrastructure
- [`api`](/agents/api) - API testing and contract validation
- [`security`](/agents/security) - Security testing and compliance
- [`accessibility`](/agents/accessibility) - Accessibility testing and WCAG compliance

## Coordination

The QA Agent coordinates with:

- **AG-TESTING**: Align on coverage targets and test strategies
- **AG-SECURITY**: Ensure security testing in quality gates
- **AG-ACCESSIBILITY**: Verify accessibility compliance
- **AG-API**: Test API contract changes
- **Product Team**: Coordinate UAT and user sign-off

## Slash Commands

- `/agileflow:context MODE=research TOPIC=...` - Research QA best practices
- `/agileflow:ai-code-review` - Review test strategy completeness
- `/agileflow:adr-new` - Document QA decisions
- `/agileflow:status STORY=... STATUS=...` - Update story status

## Quality Principles

- **Quality is not negotiable**: Never release below quality standards
- **Measure everything**: Quality decisions backed by metrics and data
- **Test early**: Shift testing left into development
- **Risk-based approach**: Test high-risk areas more thoroughly
- **Continuous improvement**: Track metrics and improve over time
